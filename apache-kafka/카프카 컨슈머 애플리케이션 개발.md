# 컨슈머 소개
---
## 컨슈머
![image](https://user-images.githubusercontent.com/60502370/205048703-36c500e2-d744-468c-b9ad-484044c6c443.png)
- 프로듀서가 전송한 데이터는 브로커에 적재된다
- 컨슈머는 브로커에 적재된 데이터를 가져와 필요한 처리를 한다

### 컨슈머 내부 구조
![image](https://user-images.githubusercontent.com/60502370/205048925-48313ab3-c651-4193-aad6-8dd17ae3258a.png)
- Fetcher: 리더 파티션으로부터 레코드들을 미리 가져와 대기
- poll(): Fetcher에 있는 레코드들을 리턴
- ConsumerRecords: 처리하고자 하는 레코드들의 모음. 오프셋이 포함되어 있다
	- ConsumerRecord들의 묶음
- commit이라는 과정으로 어느 오프셋까지 처리를 완료했는 지 알 수 있다

# 컨슈머 그룹
---
![image](https://user-images.githubusercontent.com/60502370/205051523-5e12c190-bbb3-4619-baea-9983e0883860.png)
- 컨슈머 그룹은 카프카를 운영할 때 가장 중요한 부분 중 하나이다
	- 토픽에 있는 데이터를 잘 활용해야 하는데 컨슈머 그룹을 잘 사용하면 된다
- 어느 토픽에 따라서 목적에 따라 컨슈머들을 묶은 것이 컨슈머 그룹이다
- 동일한 컨슈머 그룹에 속한 컨슈머들은 동일한 로직을 가진다
	- 가끔씩 아닌 경우도 있다
- `subscribe` 메서드를 통해 한 컨슈머가 토픽의 모든 파티션으로부터 데이터를 가져가는 것이 일반적이다
	- 컨슈머들이 적절하게 분산되어 데이터를 가져간다
- `assign` 메서드를 통하 각각의 파티션에 대해서만 데이터를 가져갈 수도 있다
- 한 컨슈머는 여러 개의 파티션에 할당 될 수 있어, 컨슈머의 개수는 토픽의 파티션 개수보다 같거나 작아야 한다
- 컨슈머와 파티션의 1대1 매칭이 가장 좋은 방법이다

## 컨슈머 그룹의 컨슈머가 파티션 개수보다 많은 경우
- 파티션을 할당 받지 못한 컨슈머는 유휴 상태로 남게된다
- 따라서 유휴 컨슈머는 스레드만 차지하고 실질적인 데이터를 처리하지 못하므로 자원을 낭비하는 셈이다

## 컨슈머 그룹을 활용하는 이유
### 컨슈머 그룹을 사용하지 않을 때
![image](https://user-images.githubusercontent.com/60502370/205053632-432412c0-5653-4e84-8b10-e21381744c58.png)
- 운영 서버의 주요 리소스인 CPU, 메모리 정보를 수집하는 데이터 파이프라인을 구축한다고 가정하자
- 실시간 리소스를 시간순으로 확인하기 위해 데이터를 엘라스틱서치와 하둡에 저장한다
- 카프카를 사용하지 않는다면 리소스 수집 에이전트는 데이터를 적재하기 위해 엘라스틱서치와 하둡에 동기적으로 요청할 것이다
- 이렇게 동기적으로 실행되는 에이전트는 엘라스틱서치와 하둡 둘 중 하나라도 장애가 발생하면 더는 적재가 불가능할 것이다

### 컨슈머 그룹을 사용하는 경우
![image](https://user-images.githubusercontent.com/60502370/205054006-c892549b-b47d-4449-805c-2b854d63a21b.png)
- 카프카를 사용하면 파이프라인을 운영함에 있어 이런 저장소 장애에 대해 유연하게 대처할 수 있다
- 프로듀서는 일단 브로커에 데이터를 전송한다
- 엘라스틱서치에 적재하는 컨슈머 그룹과 하둡에 적재하는 컨슈머 그룹을 분리한다
- 만약 엘라스틱 서치에 장애가 발생하더라도 하둡에 데이터를 문제 없이 적재할 수 있다
	- 그리고 엘라스틱서치의 장애가 해소된 후에 다시 엘라스틱서치에 데이터를 적재하면된다
- 애플리케이션의 데이터 처리량에 따라 유연하게 리소스를 설정할 수도 있다

# 리밸런싱
---
![image](https://user-images.githubusercontent.com/60502370/205055015-b6b6feb9-69e5-4fef-bbe6-4f032cb7273a.png)

- 카프카는 리밸런싱이라는 독특한 fail-over 방식을 가지고 있다
- 같은 컨슈머 그룹에 속한 컨슈머 중 일부 컨슈머에 장애가 발생하면, 장애가 발생한 컨슈머에 할당된 파티션은 다른 컨슈머에 소유권이 넘어간다
	- 이러한 과정을 리밸런싱이라 한다
- 리밸런싱이 일어나는 두 가지 상황
	- 컨슈머 추가
	- 컨슈머 제외
- 리밸런싱은 컨슈머가 데이터를 처리하는 도중에 언제든지 발생할 수 있으므로 데이터 처리 중 발생한 리밸런싱에 대응하는 코드를 작성해야 한다
	- `ConsumerRebalanceListener`를 구현해 작성할 수 있다
- 파티션이 100개, 1000개가 되면 리밸런싱 과정이 몇 십초에서 몇 분까지 걸릴 수 있는데, 이는 애플리케이션 장애 상황이라고 봐도 무방하다. 따라서 리밸런싱이 일어나지 않도록 최대한 운영해야 한다

# 커밋
---
![image](https://user-images.githubusercontent.com/60502370/205056552-923fdb01-d3f4-4ee5-aca8-13055fa6109c.png)
- 커밋은 컨슈머가 카프카 브로커로부터 데이터를 어디까지 가져갔는지 기록한다
- 어떤 파티션을 어떤 컨슈머 그룹에서 어디까지 데이터를 가져갔는 지는 카프카 브로커 내부 토픽(`__consumer_offsets`)에 저장된다
- 컨슈머 동작에 이슈가 발생해 오프셋 커밋이 기록되지 않는다면, 데이터를 중복처리할 수 있기 때문에 컨슈머가 오프셋 커밋을 정상적으로 처리했는지 검증 해야 한다

# 어사이너(Assignor)
---
- 어사이너는 컨슈머와 파티션의 할당 정책을 결정한다
- 카프카에서는 `RangeAssignor`, `RoundRobinAssignor`, `StickyAssignor`를 제공한다
	- 카프카 2.5.0는 `RangeAssignor`가 기본으로 설정되어 있다
- `RangeAssignor`: 각 토픽에서 파티션을 숫자로 정렬, 컨슈머를 사전 순서로 정렬하여 할당
- `RoundRobinAssignor`: 모든 파티션을 컨슈머에서 번갈아가며 할당
- `StickyAssignor`: 최대한 파티션을 균등하게 배분하면서 할당

# 컨슈머 주요 옵션 소개
---
## 필수 옵션

| Option             | Description                                                                               |
| ------------------ | ----------------------------------------------------------------------------------------- |
| bootstrap.server   | 컨슈머가 데이터를 가져올 카프카 클러스터에 속한 브로커의 호스트 이름:포트를 1개 이상 작성 |
| key.deserializer   | 레코드의 메시지 키를 역직렬화 하는 클래스를 작성                                          |
| value.deserializer | 레코드의 메시지 값을 역직렬화하는 클래스를 지정                                           |

- 프로듀서와 직렬화-역직렬화 포맷을 맞춰야한다

## 선택 옵션

| Option                  | Description                                                                                                                                                     |
| ----------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| grou.id                 | 컨슈머 그룹 아이디를 지정한다. `subscribe()` 메서드로 토픽을 구독하여 사용할 때는 필수다. 기본값은 null이다                                                     |
| auto.offset.reset       | 컨슈머 그룹이 특정 파티션을 읽을 때 저장된 컨슈머 오프셋이 없는 경우 어느 오프셋을 읽을지 설정. 이미 컨슈머 오프셋이 있다면 이 옵션 값은 무시. 기본값은 latest |
| enable.auto.commit      | 자동 커밋으로할 지 수동 커밋으로 할 지 선택. 기본값은 true                                                                                                      |
| auto.commit.interval.ms | 자동 커밋일 경우 오프셋 커밋 간격 지정. 기본값은 5000(5초).                                                                                                     |
| session.timeout.ms      | 컨슈머가 브로커와 연결이 끊기는 최대 시간이다. 기본값은 1000(1초).                                                                                              |
| heartbeat.interval.ms   | 하트비트를 전송하는 시간 간격이다. 기본값은 3000(3초).                                                                                                          |
| max.poll.interval.ms    | `poll()` 메서드를 호출하는 간격의 최대 시간. 기본값은 300000(5분).                                                                                              |
| isolation.level         | 트랜잭션 프로듀서가 레코드를 트랜잭션 단위로 보낼 경우 사용                                                                                                     |
| max.poll.records        | `poll()` 메서드를 통해 반환되는 레코드의 개수 지정. 기본값은 500.                                                                                                                                                                |

# auto.offset.reset
---
- 컨슈머 그룹이 특정 파티션을 읽을 때 저장된 컨슈머 오프셋이 없을 때 어느 오프셋부터 읽을지 선택하는 옵션이다
	- 이미 컨슈머 오프셋이 있다면 무시된다
- latest
	- 가장 높은(가장 최근에 넣은) 오프셋을 읽는다
- earliest
	- 가장 낮은(가장 오래전에 넣은) 오프셋을 읽는다
- none
	- 먼저 컨슈머 그룹이 커밋한 기록이 있는지 찾아본다. 커밋한 기록이 없으면 오류를 반환, 있으면 기존 커밋 기록 이후 오프셋부터 읽는다
- 기본값은 latest이다

# 수동 커밋 컨슈머 애플리케이션
---
## 동기 오프셋 커밋 컨슈머

![image](https://user-images.githubusercontent.com/60502370/205069698-612d2298-dbd8-47d0-97ba-a113d9800b33.png)
- `poll()` 메서드가 호출된 이후에 `commitSync()` 메서드를 호출하여 오프셋 커밋을 명시적으로 수행할 수 있다
- `commitSync()`는 `poll()` 메서드로 받은 가장 마지막 레코드의 오프셋을 기준으로 커밋한다
- 동기 오프셋을 사용할 경우에는 `poll()` 메서드로 받은 모든 레코드의 처리가 끝난 이후 `commitSync()` 메서드를 호출한다

## 레코드 단위 동기 오프셋 커밋 컨슈머
![image](https://user-images.githubusercontent.com/60502370/205070165-964e54b1-3fca-49b1-b7c9-044290c1663f.png)
- `Map<TopicPartition, OffsetAndMetadata>`를 `commitSync()`에 인자로 전달해야 한다
- 레코드 단위로 커밋을 하기 때문에 브로커와 네트워크 통신이 많아질 수 있어 잘 사용하지 않는다

## 비동기 오프셋 커밋 컨슈머
![image](https://user-images.githubusercontent.com/60502370/205070483-a215869f-d318-481c-8680-c6f5d679016b.png)
- 동기 오프셋 커밋을 사용하는 경우에는 커밋 응답을 받기까지 작업이 중단되기 때문에, 많은 데이터를 처리하기 위해 비동기 오프셋 커밋을 사용할 수 있다
- `commitAsync()`를 호출한다

## 비동기 오프셋 커밋 콜백
![image](https://user-images.githubusercontent.com/60502370/205070775-e0ee83bf-0de3-43d3-a1d8-9785eaf58f56.png)
- 콜백 메서드를 전달해 응답을 받지 못했을 때 처리도 할 수 있다

# 리밸런스 리스너를 가진 컨슈머 애플리케이션
---
- 카프카의 `ConsumerRebalanceListener` 인터페이스를 구현해야 한다
- `onPartitionAssigned()`: 리밸런스가 끝난 뒤에 파티션이 할당 완료되면 호출되는 메서드다
- `onPartitionRevoked()`: 리밸런스가 시작되기 직전에 호출되는 메서드다. 마지막으로  처리한 레코드를 기준으로 커밋하기 위해서는 리밸런스가 시작하기 직전에 커밋을 하면되므로, 이 메서드에 커밋을 구현하여 처리할 수 있다

# 파티션 할당 컨슈머
---
![image](https://user-images.githubusercontent.com/60502370/205073262-ef4b0d57-e3d2-4ad1-9518-f138a27fd424.png)
- group.id를 지정하지 않아야 한다

# 컨슈머 애플리케이션의 안전한 종료
---
- 컨슈머 애플리케이션은 안전하게 종료되어야 한다
- 정상적으로 종료되지 않은 컨슈머는 세션 타임아웃이 발생할 때까지 컨슈머 그룹에 남게된다
- 컨슈머를 안전하게 종료하기 위해서는 `wakeup()` 메서드를 사용한다
- `wakeup()` 메서드가 실행된 이후 `poll()` 메서드가 호출되면 `WakeupException`이 발생한다
- `WakeupException`을 받은 뒤에는 데이터 처리를 위해 사용한 자원을 해제하면 된다

![image](https://user-images.githubusercontent.com/60502370/205074172-c3f667cf-3b27-4744-828c-9fba606613c7.png)

- `Runtime.getRuntime().addShutdownHook()`을 통해 셧다운 훅을 설정해주어야 한다
- 셧다운 훅에서는 컨슈머를 안전하게 종료할 수 있게 `wakeup()` 메서드를 호출한다


# 멀티스레드 컨슈머 애플리케이션
---
- 카프카는 처리량을 늘리기 위해 파티션과 컨슈머 개수를 늘려 운영할 수 잇다
- 파티션을 여러 개로 운영하는 경우 데이터를 병렬로 처리하기 위해서 파티션의 수와 컨슈머 개수를 동일하게 맞추는 것이 좋다
- 컨슈머는 1개의 스레드를 가진 n개의 프로세스로 컨슈머를 운영할 수도 있고, n개의 스레드를 가진 1개의 컨슈머 프로세스를 운영할 수도 있다
- 멀티스레드 컨슈머는 보통 사양이 좋은 물리 서버를 가진 경우 사용한다

# 컨슈머 랙
---
- 컨슈머 랙은 파티션의 최신 오프셋(LOG-END-OFFSET)과 컨슈머 오프셋(CURRENT-OFFSET)간의 차이다
- 컨슈머랙은 컨슈머가 정상적으로 동작하는지 여부를 확인할 수 있기 때문에, 필수적인 모니터링 요소이다

## 프로듀서와 컨슈머의 데이터 처리량
- 프로듀서가 보내는 데이터의 양이 컨슈머의 데이터 처리량보다 크다면 컨슈머 랙은 늘어난다
- 그 반대는 컨슈머의 랙이 줄어들고 최소값은 0으로 지연이 없음을 나타낸다

## 컨슈머 랙 모니터링
- 컨슈머 랙을 모니터링 함으로써 컨슈머의 장애를 확인할 수도 있고, 파티션의 개수를 정하는데 참고할 수 있다
- 데이터의 양이 증가하면 일시적으로 파티션의 개수와 컨슈머의 개수를 늘려 병렬처리량을 늘릴 수도 있다
	- 파티션의 개수를 줄일 수는 없는데?

## 처리량 이슈
- 프로듀서의 데이터 양이 늘어나면 파티션과 컨슈머의 개수를 늘려서 병렬 처리량을 늘릴 수 있다

## 파티션 이슈
- 프로듀서의 데이터 양이 일정함에도 컨슈머 장애로 컨슈머 랙이 증가할 수도 있다
- 특정 파티션의 컨슈머 랙이 늘어난다면 해당 파티션이 할당된 컨슈머에 이슈가 있음을 유추할 수 있다

# 컨슈머 랙 모니터링
---
## 카프카 명령어 사용
- `kafka-consumer-groups.sh --bootstrap-server my-kafka:9092 --group my-group --describe`
- 명령어를 통해 컨슈머랙을 확인하는 방법은 일회성에 그치고 지표를 지속적으로 기록하고 모니터링 하기에는 부족하다

## metrics()
- 컨슈머 애플리케이션에서 `metrics()` 메서드를 사용하면 컨슈머 랙 지표를 확인할 수 있다

```Java
for(Map.Entry<MetricName, ? extends Metric> entry : kafkaConsumer.metrics().entrySet()) {
	if ("records-lag-max".equals(entry.getKey().name()) ||
		"records-lag".equals(entry.getKey().name()) ||
		"records-lag-avg".equals(entry.getKey().name())) {
		Metric metric = entry.getValue();
		logger.info("{}: {}", entry.getKey().name(), metric.metricValue());		
	}

}
```

- 컨슈머가 정상 동작하는 경우에만 `metrics()` 메서드를 사용할 수 있다
- 모든 컨슈머 애플리케이션에 컨슈머 랙 모니터링 코드를 중복해서 사용해야 한다
- 컨슈머 랙 모니터링 코드를  추가할 수 없는 카프카 서드 파티 애플리케이션의 컨슈머 랙 모니터링이 불가능하다

## 외부 모니터링 툴 사용
- 컨슈머 랙을 모니터링 하는 최선의 방법은 외부 모니터링 툴을 사용하는 것이다
- 데이터 독, 컨플루언트 컨트롤 센터가 있다
- 컨슈머 랙 모니터링만을 위한 툴은 버로우가 있다

# 버로우
---
- 링크드인에서 개발한 오픈소스 컨슈머 랙 모니터링 툴
- REST API를 통해 컨슈머 그룹별로 컨슈머 랙을 확인할 수 있다
- 카프카 클러스터에 연결된 모든 컨슈머, 토픽들의 랙 정보를 한 번에 모니터링 할 수 있다
- 컨슈머의 데이터 처리와는 별개로 지표를 수집해 데이터를 활용하는 프로듀서나 컨슈머의 동작에 영향을 미치지 않는다

## 컨슈머 랙 이슈 판별
- 버로우는 컨슈머와 파티션의 상태를 단순히 컨슈머 랙의 임계치로 나타내지 않는다
	- 특정 시점에 100만이 넘었다고 컨슈머나 파티션에 이슈가 있다고 단정 지을 수 없기 때문이다
- 슬라이딩 윈도우 계산을 통해 문제가 생긴 파티션과 컨슈머의 상태를 표현한다
	- 컨슈머 랙 평가(evaluation)이라 한다
	- 파티션의 상태를 OK, STALLED, STOPPED로 표현한다
	- 컨슈머의 상태를 OK, WARNNING, ERROR로 표현한다

### 정상적인 경우
 ![[Pasted image 20230328082902.png]]
 - 프로듀서가 지속적으로 데이터를 추가하고, 최신 오프셋은 계속해서 증가한다
 - 파티션 OK, 컨슈머 OK

### 컨슈머 처리량 이슈
![[Pasted image 20230328083002.png]]
- 프로듀서가 추가하는 최신 오프셋에 비해 컨슈머 오프셋이 따라가지 못하는 추이
- 프로듀서의 데이터 양보다 컨슈머의 데이터 처리량이 적은 현상이다
- 파티션 OK, 컨슈머 WARNNING

### 컨슈머 이슈
![[Pasted image 20230328083122.png]]
- 컨슈머 오프셋이 멈추어 컨슈머 랙이 급격하게 증가한 경우
- 컨슈머가 어떠한 이유로 데이터를 가져가지 않는 상태
- 파티션 STALLED, 컨슈머 ERROR
	- 파티션의 상태가 STALLED인 것은 파티션의 데이터가 현재 처리되지 않고 있다는 상태
	- 컨슈머 상태가 ERROR인 경우 알람을 보내고 즉각 조치해야 한다
