# 아파치 카프카 생태계
---
![Screen Shot 2022-11-27 at 3 29 06 PM](https://user-images.githubusercontent.com/60502370/204122443-f4142adb-4f85-46e3-9dc4-57f1247d4c40.png)

# 카프카 브로커와 클러스터
---
## 카프카 브로커, 클래스터, 주키퍼

![image](https://user-images.githubusercontent.com/60502370/204122591-973f3f13-5adc-41f1-bd8b-b6fc780b4326.png)

### 카프카 브로커
- 카프카 클라이언트와 데이터를 주고받기 위해 사용하는 주체
- 데이터를 분산 저장하여 장애가 발생하더라도 안전하게 사용할 수 있도록 도와주는 애플리케이션이다
- 하나의 서버에는 한 개의 카프카 브로커 프로세스가 실행된다
- 카프카 브로커 1개로도 기본 기능이 실행되지만, 데이터를 안전하게 보관하고 처리하기 위해 3대 이상의 브로커를 1개의 클러스터로 묶어서 운영한다

### 주키퍼
- 주키퍼는 분산 애플리케이션을 위한 코디네이션 시스템이다
- 분산 애플리케이션이 안정적인 서비스를할 수  있도록 분산되어 있는 각 애플리케이션의 정보를 중앙에 집중하고 구성 관리, 그룹 관리 네이밍, 동기화 등의 서비스를 제공한다

![image](https://user-images.githubusercontent.com/60502370/204122738-95264d63-392d-4b69-b462-4c562b0c2b9a.png)

- Server는 주키퍼, Client는 카프카이다
- 서버 여러대를 앙상블(클러스터)로 구성하고, 분산 애플리케이션들이 각각 클라이언트가 되어 주키퍼 서버들과 커넥션을 맺은 후 상태 정보 등을 주고 받는다
- 상태 정보들은 주키퍼의 지노드라는 곳에 key-value 형태로 저장한다
- 지노드에 저장된 것을 이용하여 분산 애플리케이션들은 서로 데이터를 주고 받게된다


## 여러개의 카프카 클러스터와 연결된 주키퍼
![image](https://user-images.githubusercontent.com/60502370/204122842-a4620625-50a3-4b62-9a11-addf6bfaba4b.png)
- 루트 지노드에 각 클러스터별 지노드를 생성하고 클러스터 실행시 루트가 아닌 하위 지노드로 설정한다
- 카프카 3.0부터는 주키퍼가 없어도 클러스터가 동작가능하다
	- 현재는 완벽하지 않고 차차 없어질 예정이다

## 브로커의 역할
### 컨트롤러
- 클러스터의 다수 브로커 중 하나가 컨트롤러 역할을 한다
- 컨트롤러는 다른 브로커의 상태를 체크한다
- 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 리더 파티션을 재분배한다
- 컨트롤러 역할을 하는 브로커에 장애가 생기면 다른 브로커가 컨트롤러 역할을 한다

### 데이터 삭제
- 카프카는 컨슈머가 파티션에서 데이터를 읽더라도 데이터가 삭제되지 않는다
- 컨슈머나 프로듀서가 데이터 삭제를 요청할 수도 없고, 오직 브로커만이 데이터를 삭제할 수 있다
- 데이터 삭제는 파일 단위로 이루어지는데 이 단위를 로그 세그먼트라 한다
	- `delete` 옵션에 의해서 일정 시간, 용량에 따라서 삭제할 수 있다
	- `compact`라는 옵션을 사용해 가장 최신의 메시키가 존재하는 레코드를 제외한 다른 레코드를 삭제할 수 있다

## 컨슈머 오프셋 저장
- 컨슈머 그룹은 토픽이 특정 파티션으로부터 데이터를 가져가서 처리하고 이 파티션의 어느 레코드까지 가져갔는지 확인하기 위해 오프셋을 커밋한다
- 커밋한 오프셋은 `__consumer_offsets`토픽에 저장한다
- 여기에 저장된 오프셋을 토대로 컨슈머 그룹은 다음 레코드를 가져가서 처리한다

## 코디네이터
- 코디네이터는 컨슈머 그룹의 상태를 체그하고 파티션을 컨슈머와 매칭되도록 분배하는 역할을 한다
- 컨슈머가 컨슈머 그룹에서 빠지면 매칭되지 않는 파티션을 정상 동작하는 컨슈머로 할당하여 끊임없이 데이터가 처리되도록 도와준다
	- 이러한 과정을 '리밸런스'라고 한다

## 데이터 저장
- 카프카를 실행할 때 `config/server.properties`의 `log.dir` 옵션에 정의한 디렉토리에 데이터를 저장한다
	- 토픽 이름과 파티션 번호의 조합으로 하위 디렉토리를 생성하여 데이터를 저장한다
- hello.kafka 토픽의 0번 파티션에 존재하는 데이터를 확인할 수 있다
	- log에는 메시지와 메타데이터를 저장한다
	- index는 메시지의 오프셋을 인덱싱한 정보를 담은 파일이다
	- timeindex 파일에는 메시지에 포함된 timestamp값을 기준으로 인덱싱한 정보를 가지고 있다
![image](https://user-images.githubusercontent.com/60502370/204123746-5f5d932c-8a2d-46d5-b8e2-5c776c62599a.png)

### 로그와 세그먼트
- log.segment.bytes: 바이트 단위의 최대 세그먼트 크기 지정. 기본값은 1GB
- log.roll.ms(hours): 세그먼트가 신규 생성된 이후 다음 파일로 넘어가는 시간 주기. 기본값은 7일

### 액티브 세그먼트
![image](https://user-images.githubusercontent.com/60502370/204123783-76859ca2-ccfc-4626-bd23-5efba73c6099.png)

- 가장 마지막 세그먼트 파일을 액티브 세그먼트라 한다
- 액티브 세그먼트는 브로커의 삭제 대상에서 포함되지 않는다
- 액티브 세그먼트가 아닌 세그먼트는 retention 옵션에 따라 삭제 대상으로 처리된다

### 세그먼트의 삭제(cleanup.policy=delete)
- 카프카에서 데이터는 세그먼트 단위로 삭제가 발생한다
	- 로그 단위(레코드 단위)로 개별 삭제는 불가능하다
- 로그의 메시지 키, 메시지 값, 오프셋, 헤더 등 이미 적재된 데이터에 대해서는 수정이 불가능하다
	- 데이터를 적재할 때나 사용할 때는 검증을 수행하는 것이 중요하다

### cleanup.policy=compact
![image](https://user-images.githubusercontent.com/60502370/204124108-1c3dc8eb-912c-4d71-bbda-0eb57f1d060a.png)

- 메시지 키 별로 해당 메시지 키의 레코드 중 오래된 데이터를 삭제하는 정책을 말한다
- 삭제 정책과는 다르게 일부 레코드만 삭제가 될 수 있다
- 압축은 액티브 세그먼트를 제외한 데이터가 대상이다

### 테일/헤드 영역,  클린/더티 로그
![image](https://user-images.githubusercontent.com/60502370/204124156-e45d7234-c2c4-4b93-b454-53cffed292a6.png)
- 테일 영역: 압축 정책에 의해 압축이 완료된 레코드들. 클린로그 라고도 부른다. 중복 메시지 키가 없다
- 헤드 영역: 압축이 적용되기 전 레코드들. 더티로그 라고도 부른다. 중복된 메시지 키가 있다

### min.cleanable.dirty.ratio
![image](https://user-images.githubusercontent.com/60502370/204124190-956ef327-2dfa-40da-8c1f-319cbcf2dfe2.png)
- 데이터의 압축 시작 시점은 `min.cleanable.dirty.ratio` 옵션값을 따른다
- `min.cleanable.dirty.ratio`는 액티브 세그먼트를 제외한 세그먼트에 남아있는 테일 영역의 레코드 개수와 헤드 영역의 레코드 개수 비율을 나타낸다
- 예를 들어, 0.5로 설정한다면 테일 영역의 레코드개수가 헤드 영역의 레코드 개수와 동일할 경우 압축이 실행된다
- 0.9처럼 크게 설정하면 한 번 압축을 할 때 많은 데이터가 줄어들어 압축효과가 좋지만, 0.9 비율이 될 때까지 용량을 차지하므로 용량 효율이 좋지 않다
- 0.1처럼 작게 설정하면 압축이 자주 일어나 최신의 데이터를 유지할 수 있지만, 압축이 자주 발생하여 브로커에 부담을 줄 수 있다

## 복제(Replication)
![image](https://user-images.githubusercontent.com/60502370/204125638-753048f7-6d7e-45a7-ad94-fe72ac7e9cff.png)

- 데이터 복제(Replication)는 카프카를 장애 허용 시스템(fault tolerant system)으로 동작하는 원동력이다
- 복제의 이유는 클러스터 내부의 브로커 중 일부에 장애가 발생하더라도 데이터를 유실하지 않고 안전하게 사용하기 위함이다
- 카프카의 복제는 파티션 단위로 이루어진다
	- 프로듀서와 컨슈머와 직접 통신하는 파티션을 리더 파티션, 그 외 파티션을 팔로워 파티션이라 한다
	- 팔로워 파티션은 리더 파티션의 오프셋을 확인해서 현재 자신이 가지고 있는 오프셋과 차이나는 경우, 리더의 데이터를 가져와 저장한다
- 토픽을 생성할 때 파티션의 복제 개수(Replication factor)도 같이 설정한다
	- 옵션을 선택하지 않으면 브로커에 설정된 옵션을 따른다
	- 복제 개수의 최소값은 1이고 최대값은 브로커의 개수를 따른다
	- 데이터를 안전하게 사용할 수 있도록 복제 개수를 2로 설정하는 것이 좋다
	- 네비게이션 애플리케이션과 같이 GPS 데이터는 일부 데이터가 유실되어도 무관하여 1로 설정할 수 있다
	- 금융 정보와 같이 유실이 일어나면 안되는 데이터의 경우 복제 개수를 3으로 설정하기도 한다

### ISR(In-Sync-Replicas)
- ISR은 리더 파티션과 팔로워 파티션이 모두 싱크가 된 상태를 말한다
- 리더 파티션에 0부터 3의 오프셋이 있다고 가정할 때, 팔로워 파티션에 동기화가 완료되려면 0부터 3까지 오프셋이 존재해야 한다

#### unclean.leader.election.enable
![image](https://user-images.githubusercontent.com/60502370/204126048-bb9e9539-f7fb-44fa-a35f-7ce7eda28dd0.png)
- 리더 파티션의 데이터를 모두 복제하지 못한 상태일 때, 팔로워 파티션이 리더 파티션으로 선출이되면 데이터가 유실 될 수 있다
- 유실이 발생하더라도 서비스를 중단하지 않고 지속적으로 토픽을 사용하고 싶다면 ISR이 아닌 팔로워 파티션을 리더로 선출할 수 있도록 설정할 수 있다
	- unclean.leader.election.enable=true: 유실을 감수함. 복제가 안된 팔로워 파티션을 리더로 승급
	- unclean.leader.election.enable=false: 유실을 감수하지 않음. 해당 브로커가 복구될 때까지 중단

# 토픽, 파티션, 레코드
---

## 토픽과 파티션
![image](https://user-images.githubusercontent.com/60502370/204126379-3185bcbe-8a7e-4155-b03f-e33094d6368a.png)
- 토픽은 카프카에서 데이터를 구분하기 위해 사용하는 단위이다
	- 토픽은 1개 이상의 파티션을 가지고 있다
- 파티션은 프로듀서가 보낸 데이터가 저장된다
	- 파티션은 자료구조에서 접하는 큐와 유사한 구조이다
	- FIFO 구조와 같이 먼저 들어간 레코드는 컨슈머가 먼저 가져간다
	- 일반적인 큐에서는 데이터를 가져가면 삭제되지만, 카프카는 삭제되지 않는다
- 레코드는 파티션에 저장된 데이터를 말한다
	- 파티션의 레코드는 컨슈머가 가져가는 것과 별개로 관리된다
- 토픽 레코드는 다양한 목적을 가진 여러 컨슈머 그룹들이 토픽의 데이터를 여러번 가져갈 수 있다

## 토픽 생성시 파티션이 배치되는 방법
![image](https://user-images.githubusercontent.com/60502370/204126498-46e701b6-7ca2-4148-ac50-5d7f6f61f784.png)
- 파티션이 5개인 토픽을 생성할 경우 0번 브로커에서 시작해서 round-robin 방식으로 리더 파티션들이 생성된다
- 카프카 클라이언트는 리더 파티션과 통신하므로 여러 브로커에 골고루 네트워크 통신을 하게된다
- 데이터가 특정 서버와 통신이 집중되는 현상(Hot spot) 선형 확장(linear scale out)을 하여 데이터가 많아지더라도 자연스럽게 대응할 수 있게된다

![image](https://user-images.githubusercontent.com/60502370/204126587-0b6a079f-1e83-455c-9caf-cb4efbaab3d8.png)

#### 특정 브로커에 파티션이 쏠리는 현상
![image](https://user-images.githubusercontent.com/60502370/204126632-b084ea40-2952-4b2c-ace8-0ff2b796c811.png)
- 특정 브로커에 파티션이 몰리는 경우에는 `kafka-reassign-partition.sh` 명령으로 파티션을 재분배할 수 있다

### 파티션 개수와 컨슈머 개수의 처리량
![image](https://user-images.githubusercontent.com/60502370/204126665-0ebaab7e-fb7d-4c2b-b166-d2504b6a8338.png)
- 파티션은 카프카의 병렬처리의 핵심으로, 그룹으로 묶인 컨슈머들이 레코드를 병렬로 처리할 수 있도록 매칭된다
- 컨슈머의 처리량이 한정된 상황에서 많은 레코드를 병렬로 처리하는 가장 좋은 방법은 컨슈머의 개수를 늘려 스케일 아웃 하는 것이다
- 가장 이상적인 것은 파티션 하나에 컨슈머 하나가 할당되는 것이다
- 하지만 현재 카프카는 파티션의 개수를 줄이는 방법을 제공하지 않는다
	- 토픽을 삭제하고 재생성하는 방법외에는 파티션을 줄이는 방법이 존재하지 않는다

# 레코드 
---
![image](https://user-images.githubusercontent.com/60502370/204126984-31689f8b-1ec0-4208-abe3-0411e44d795c.png)
- 레코드는 타임스탬프, 헤더, 메시지 키, 메시지 값, 오프셋으로 구성되어 있다
- 프로듀서가 생성한 레코드가 브로커로 전송되면 오프셋과 타임스탬프가 지정되어 저장된다
- 브로커에 한 번 적재된 레코드는 수정할 수 없고 로그 리텐션 기간 또는 용량에 따라서만 삭제된다

## 타임스탬프
- 레코드의 타임스탬프는 스트림 프로세싱에서 활용하기 위한 시간을 저장하는 용도로 사용된다
- 카프카 0.10.0.0 이후 버전부터 추가된 타임 스탬프는 Unix timestamp가 포함되며 프로듀서에서 따로 설정하지 않으면 기본값으로 ProducerRecord 생성 시간이 들어간다
	- 혹은 브로커 적재 시간으로 설정할 수도 있다
	- 해당 옵션은 토픽 단위로 설정 가능하며 `message.timestamp.type`을 사용한다

## 오프셋
- 레코드의 오프셋은 프로듀셔가 생성한 레코드에는 존재하지 않는다
- 프로듀서가 전송한 레코드가 브로커에 적재될 때 오프셋이 지정된다
- 오프셋은 0부터 시작되고 1씩 증가한다
- 컨슈머는 오프셋을 기반으로 처리가 완료된 데이터와 앞으로 처리할 데이터를 구분한다
- 각 메시지는 파티션별로 고유한 오프셋을 가지므로 컨슈머에서 중복 처리를 방지하기 위한 목적으로 사용한다

## 헤더
- 레코드의 헤더는 0.11 부터 제공된 기능이다
- key/value 데이터를 추가할 수 있다
- HTTP Header 처럼 레코드의 스키마 버전등 프로세싱에 도움이 될만한 정보들을 담을 수 있다

## 메시지 키
- 메시지 키는 처리하고자 하는 메시지 값을 분류하기 위한 용도로 사용되며, 이를 파티셔닝이라 한다
- 파티셔닝에 사용하는 메시지 키는 파티셔너에 따라 토픽의 파티션 번호가 정해진다
- 메시지 키는 필수 값이 아니며 지정하지 않으면 null로 설정된다
	- 메시지 키가 null인 레코드는 특정 토픽의 파티션에 라운드 로빈으로 전달된다

## 메시지 값
- 메시지 값은 실질적으로 처리할 데이터가 담기는 공간이다
- 메시지 값은 포맷은 제네릭으로 사용자에 의해 지정된다
- Float, Byte[], String등 다양한 혀앹로 지정 가능하며, 필요에 따라 사용자 지정 포맷으로 직렬화/역직렬화 클래스를 만들어 사용할 수 있다
- 브로커에 저장된 레코드의 메시지 값은 어떤 포맷으로 직렬화되어 저장되었는지 알 수 없기 때문에 컨슈머는 미리 직렬화 포맷을 알고 있어야 한다
- 

# 유지보수하기 좋은 토픽 이름
---
- 생략

# 카프카 브로커와 클라이언트가 통신하는 방법
---
## 클라이언트 메타데이터
- 카프카 클라이언트는 통신하고자 하는 리더 파티션의 위치를 알기 위해 메타데이터를 브로커로부터 전달 받는다
- 메타데이터는 다음과 같은 옵션을 통해 리프래시된다
- 카프카 프로듀서 메타데이터 옵션
	- metadata.max.age.ms: 메타데이터를 강제로 리프래시하는 간격. 기본값 5분
	- metadata.max.idle.ms: 프로듀서가 유휴상태일 경우 메타데이터를 개시에 유지하는 기간

## 클라이언트 메타데이터에 이슈가 발생한 경우
- 카프카 클라이언트는 반드시 리더 파티션과 통신해야 한다
- 만약 메타데이터가 현재의 파티션 상태에 맞게 리프래시되지 않은 상태에서 잘못된 브로커로 데이터를 요청하면 `LEADER_NOT_AVAILABLE` 예외가 발생한다
	- 이 예외는 클라이언트가 데이터를 요청한 브로커에 리더 파티션이 없는 경우 나타내며, 대부분의 경우 메타데이터 리프래시 이슈로 발생한다
- 이 예외가 자주 발생하면 메타데이터 리프래시 간격을 확인하고 클라이언트가 정상적인 메타데이터를 가지고 있는 지 확인해야 한다