## 1. Chunk란?
- Spring Batch에서 Chunk란 데이터 덩어리로, 작업할 때 각 커밋 사이에서 처리되는 row의 수를 말한다
- Chunk 지향 처리란 한 번에 하나씩 데이터를 읽어 Chunk라는 덩어리를 만든 뒤, Chunk 단위로 트랜잭션을 다루는 것을 의미한다
- Chunk 지향  처리에서는 트랜잭션이 실패할 경우 해당 Chunk  롤백이 된다

- Chunk 지향 처리를 그림으로 표현하면 아래와 같다

![image](https://user-images.githubusercontent.com/60502370/215252595-a3640389-96f4-41f8-aa5c-abd54d124bc9.png)
- ItemReader에게서 Item 하나를 읽어 온다
- ItemProcessor가 Item 하나를 가공한다
- 가공된 Item을 별도의 공간에 모은 뒤, Chunk 단위만큼 쌓이게되면 ItemWriter가 일괄 저장한다
- **ItemReader와 ItemProcessor가 1건의 Item을 다루고, ItemWriter는 Chunk 단위로 처리된다**

## 2. ChunkOrientedTasklet
- `ChunkOrientedTasklet`는 Chunk 지향 처리의 전체 로직을 다룬다

```Java
public RepeatStatus execute(StepContribution contribution, ChunkContext chunkContext) throws Exception {  
  
   @SuppressWarnings("unchecked")  
   Chunk<I> inputs = (Chunk<I>) chunkContext.getAttribute(INPUTS_KEY);  
   if (inputs == null) {  
      inputs = chunkProvider.provide(contribution); // 1
      if (buffering) {  
         chunkContext.setAttribute(INPUTS_KEY, inputs);  
      }  
   }  
  
   chunkProcessor.process(contribution, inputs); // 2
   chunkProvider.postProcess(contribution, inputs);  
  
   // Allow a message coming back from the processor to say that we  
   // are not done yet   if (inputs.isBusy()) {  
      logger.debug("Inputs still busy");  
      return RepeatStatus.CONTINUABLE;  
   }  
  
   chunkContext.removeAttribute(INPUTS_KEY);  
   chunkContext.setComplete();  
  
   if (logger.isDebugEnabled()) {  
      logger.debug("Inputs not busy, ended: " + inputs.isEnd());  
   }  
   return RepeatStatus.continueIf(!inputs.isEnd());  
  
}
```
1. ItemReader에서 데이터를 가져온다
2. ItemProcessor와 ItemWriter로 데이터를 가공하고 저장한다

```Java
public Chunk<I> provide(final StepContribution contribution) throws Exception {  
  
   final Chunk<I> inputs = new Chunk<>();  
   repeatOperations.iterate(new RepeatCallback() {  // 1
  
      @Override  
      public RepeatStatus doInIteration(final RepeatContext context) throws Exception {  
         I item = null;  
         Timer.Sample sample = Timer.start(Metrics.globalRegistry);  
         String status = BatchMetrics.STATUS_SUCCESS;  
         try {  
            item = read(contribution, inputs);  // 2
         }  
         catch (SkipOverflowException e) {  
			status = BatchMetrics.STATUS_FAILURE;  
            return RepeatStatus.FINISHED;  
         }  
         finally {  
            stopTimer(sample, contribution.getStepExecution(), status);  
         }  
         if (item == null) {  
            inputs.setEnd();  
            return RepeatStatus.FINISHED;  
         }  
         inputs.add(item);  // 3
         contribution.incrementReadCount();  
         return RepeatStatus.CONTINUABLE;  
      }  
  
   });  
  
   return inputs;  
  
}
```
1. `iterate()` 반복자로 반복한다
2. Item을 가져온다
3. 반복자가 끝날때 까지 `inputs`에 저장한다

- `provider()`는 ItemReader에서 1건씩 데이터를 조회해 Chunk size만큼 데이터를 쌓는 역할을 한다

## 3.  SimpleChunkProcessor
- ItemProcessor와 ItemWriter 로직을 담고있는 것이 `ChunkProcessor`이다
- `SimpleChunkProcessor`는 `ChunkProcessor`의 기본 구현체이다
```Java
public final void process(StepContribution contribution, Chunk<I> inputs) throws Exception {  
  
   // Allow temporary state to be stored in the user data field  
   initializeUserData(inputs);  
  
   // If there is no input we don't have to do anything more  
   if (isComplete(inputs)) {  
      return;  
   }  
  
   // Make the transformation, calling remove() on the inputs iterator if  
   // any items are filtered. Might throw exception and cause rollback.
   Chunk<O> outputs = transform(contribution, inputs); // 1
  
   // Adjust the filter count based on available data  
   contribution.incrementFilterCount(getFilterCount(inputs, outputs));  
  
   // Adjust the outputs if necessary for housekeeping purposes, and then  
   // write them out...   
   write(contribution, inputs, getAdjustedOutputs(inputs, outputs)); // 2
  
}
```
1. Chunk size만큼 쌓인 item인 `inputs`를 전달 받아 `doProcess()`에게 전달해 변환된 값을 받는다
2. `transform()`을 통해 가공된 대량의 데이터가 `write()`를 통해 일괄 저장된다
   - `write()`는 구현에 따라 데이터베이스에 일괄 저장될 수 있고, 외부 API로 전송될 수 있다

```Java
protected Chunk<O> transform(StepContribution contribution, Chunk<I> inputs) throws Exception {  
   Chunk<O> outputs = new Chunk<>();  
   for (Chunk<I>.ChunkIterator iterator = inputs.iterator(); iterator.hasNext();) {  
      final I item = iterator.next();  
      O output;  
      Timer.Sample sample = BatchMetrics.createTimerSample();  
      String status = BatchMetrics.STATUS_SUCCESS;  
      try {  
         output = doProcess(item); // 1
      }  
      catch (Exception e) {  
         inputs.clear();  
         status = BatchMetrics.STATUS_FAILURE;  
         throw e;  
      }  
      finally {  
         stopTimer(sample, contribution.getStepExecution(), "item.process", status, "Item processing");  
      }  
      if (output != null) {  
         outputs.add(output);  
      }  
      else {  
         iterator.remove();  
      }  
   }  
   return outputs;  
}
```
1. Item 하나를 가공한다

```Java
protected final O doProcess(I item) throws Exception {  
  
   if (itemProcessor == null) {  
      @SuppressWarnings("unchecked")  
      O result = (O) item;  
      return result;  
   }  
  
   try {  
      listener.beforeProcess(item);  
      O result = itemProcessor.process(item); // 1
      listener.afterProcess(item, result);  
      return result;  
   }  
   catch (Exception e) {  
      listener.onProcessError(item, e);  
      throw e;  
   }  
  
}
```
1. ItemProcessor를 통해 Item을 가공한다

- `write()`도 비슷하게 내부적으로 `doWrite()`를 호출하고, ItemWriter가 데이터를 일괄 저장한다

```Java
protected void writeItems(List<O> items) throws Exception {  
   if (itemWriter != null) {  
      itemWriter.write(items);  
   }  
}
```

## 4. Page size VS Chunk size
- Page size와 Chun size는 서로 의미하는 바가 다르다
- Chunk Size는 한 번에 처리될 트랜잭션 단위를 말한다
- Page Size는 한 번에 조회할 Item의 양을 말한다

- PagingItemReader의 부모 클래스는 `AbstractItemCountingItemStreamItemReader`의 `read`메서드를 살펴보면 다음과 같다

```Java
public T read() throws Exception, UnexpectedInputException, ParseException {  
   if (currentItemCount >= maxItemCount) {  
      return null;  
   }  
   currentItemCount++;  
   T item = doRead(); // 1
   if(item instanceof ItemCountAware) {  
      ((ItemCountAware) item).setItemCount(currentItemCount);  
   }  
   return item;  
}
```
1. `doRead`를 호출해 Item을 가져온다

- `AbstractPagingItemReader`에 구현된 `doRead()`는 다음과 같다

```Java
protected T doRead() throws Exception {  // 1
  
   synchronized (lock) {  
  
      if (results == null || current >= pageSize) {  // 2
  
         if (logger.isDebugEnabled()) {  
            logger.debug("Reading page " + getPage());  
         }  
  
         doReadPage();  // 3
         page++;  
         if (current >= pageSize) {  
            current = 0;  
         }  
  
      }  
  
      int next = current++;  
      if (next < results.size()) {  
         return results.get(next);  
      }  
      else {  
         return null;  
      }  
  
   }  
  
}
```
1. 현재 읽어올 데이터가 없거나, Page size를 초과한 경우 `doReadPage()`를 호출한다
2. `results == null`은 읽어올 데이터가 없는 경우이다. 이는 read가 처음 시작할 때를 의미한다.
   `current >= pageSize`는 Current Position이 Page Size를 초과한 경우이다. 예를 들어 Page size가 10인데 Current Position이 11인 경우이다
3. `doReadPage()`를 호출한다. 이 메서드는 하위 구현 클래스에서 각자만의 방식으로 구현된 페이징 쿼리를 생성한다

- JdbcPagingItemReader의 동작 방식은 [여기](https://ojt90902.tistory.com/785) 를 참고할 것

